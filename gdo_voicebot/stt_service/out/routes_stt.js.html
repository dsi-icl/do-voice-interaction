<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Source: routes/stt.js</title>

    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">

    <h1 class="page-title">Source: routes/stt.js</h1>

    



    
    <section>
        <article>
            <pre class="prettyprint source linenums"><code>/**
 * @file Manages some deepspeech utilities functions
 * @author Aurélie Beaugeard
*/

/* const Fs = require("fs"); */
/* var FileWriter = require("wav").FileWriter; */
/**
 * 
 */
const DeepSpeech = require("deepspeech");

/**
 * Function that returns the transcription of an audioBuffer using deepspeech node.
 * 
 * @param {Buffer} audioBuffer The audioBuffer to be transcripted (parameters to be verified : mono-channel,16000 Hz (sample rate), 16 bit PCM)
 * @param {DeepSpeech.Model} model The deepspeech model used to convert the speech to text
 * @returns {String} The text message from the user
 * @see {@link https://deepspeech.readthedocs.io/en/v0.7.4/NodeJS-API.html|DeepSpeech}
 */
export function speech_to_text(audioBuffer,model) {


    /*  if (!Fs.existsSync(audioFile)) {
        console.log("file missing:", audioFile);
        process.exit();
        }

    const buffer = Fs.readFileSync(audioFile); */

    let result = model.stt(audioBuffer);
    
    return result;

}

/**
 * Function that returns a pre-constructed DeepSpeech Model object
 * 
 * @description DEEPSPEECH VERSION: 0.7.4,
 * @description BEAM_WIDTH: 1024,
 * @description LM_ALPHA: 0.75,
 * @description LM_BETA: 1.85,
 * @see {@link https://deepspeech.readthedocs.io/en/v0.7.4/NodeJS-API.html|DeepSpeech}
 * @returns {DeepSpeech.Model}The model to be used for the transcription
 */
export function loadDeepSpeechModel() {

    const BEAM_WIDTH = 1024;
    let modelPath = "./src/models/deepspeech-0.7.4-models.pbmm";

    let model = new DeepSpeech.Model(modelPath);
    model.setBeamWidth(BEAM_WIDTH);

    const LM_ALPHA = 0.75;
    const LM_BETA = 1.85;
    let scorerPath = "./src/models/deepspeech-0.7.4-models.scorer";

    model.enableExternalScorer(scorerPath);
    model.setScorerAlphaBeta(LM_ALPHA,LM_BETA);

    return model;

}


/* export async function getAudio() {

    const writer = new FileWriter("./src/audio/test.wav", {
        sampleRate: 16000,
        channels: 1,
        bitDepth: 16
    });

    const response = await Axios({
        method: "GET",
        url: "http://localhost:4000/voice-assistant/record",
        responseType: "stream"
    });

    response.data.pipe(writer);

    return new Promise((resolve, reject) => {
        writer.on("finish", resolve);
        writer.on("error", reject);
    });

}
 */</code></pre>
        </article>
    </section>




</div>

<nav>
    <h2><a href="index.html">Home</a></h2><h3>Global</h3><ul><li><a href="global.html#DeepSpeech">DeepSpeech</a></li><li><a href="global.html#Gettingservicestatus">Getting service status</a></li><li><a href="global.html#Gettingthetestresult">Getting the test result</a></li><li><a href="global.html#isEmpty">isEmpty</a></li><li><a href="global.html#loadDeepSpeechModel">loadDeepSpeechModel</a></li><li><a href="global.html#sampleData">sampleData</a></li><li><a href="global.html#Speech-To-Texttranscriptionpost">Speech-To-Text transcription post</a></li><li><a href="global.html#speech_to_text">speech_to_text</a></li></ul>
</nav>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc/jsdoc">JSDoc 3.6.5</a> on Thu Jul 30 2020 21:23:12 GMT+0200 (heure d’été d’Europe centrale)
</footer>

<script> prettyPrint(); </script>
<script src="scripts/linenumber.js"> </script>
</body>
</html>
